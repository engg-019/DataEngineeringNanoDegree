{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Databases\n",
    "\n",
    "### Definition\n",
    "A set of related data and the way it is organized\n",
    "\n",
    "### Database Management System\n",
    "\"... consisting of **compuer software** that allows users to interact with the databases and provides access to all of the data. Because of the **close relationship** the term database is often used to refer to both the database and the DBMS used.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Impotance of Relational Databases\n",
    "* Invented in 1969 by researchers at IBM. Edgar R.Codd, the lead researcher, proposed 12 rules of what makes a DBMS a true relational system.\n",
    "\n",
    "**Rule 1**: The information rule:\n",
    "All information in a relational database is represented explicitly at the logical level and in exactly one way â€“ by values in tables.\n",
    "\n",
    "**More information on Codd's 12 Rules can be found here:**\n",
    "[Wikipedia link](https://en.wikipedia.org/wiki/Codd%27s_12_rules)\n",
    "\n",
    "### Relational Importance\n",
    "* **Standardization of data model**: Once your data is transformed into the rows and columns format, your data is standardized and you can query it with SQL\n",
    "* **Flexibility in adding and altering tables**: Relational databases gives you flexibility to add tables, alter tables, add and remove data.\n",
    "* **Data Integrity**: Data Integrity is the backbone of using a relational database.\n",
    "* **Standard Query Language (SQL)**: A standard language can be used to access the data with a predefined language.\n",
    "* **Simplicity** : Data is systematically stored and modeled in tabular format.\n",
    "* **Intuitive Organization**: The spreadsheet format is intuitive but intuitive to data modeling in relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OLAP vs OLTP\n",
    "### WHat is OLAP vs OLTP?\n",
    "**Online Analytical Processing(OLAP)**:  \n",
    "Databases optimized for there workloads allow for **complex analytical and ad hoc queries**. These types of databases are optimized for reads.  \n",
    "\n",
    "**Online Transactional Processing(OLTP)**:\n",
    "Databases optimized for these workloads allow fo **less complex queries in large volume**. The types of queries for these databases are read, insert, update and delete.  \n",
    "\n",
    "The key to remember the difference between OLAP and OLTP is analytics (A) vs transactions (T). If you want to get the price of a shoe then you are using OLTP (this has very little or no aggregations). If you want to know the total stock of shoes a particular store sold, then this requires using OLAP (since this will require aggregations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 1\n",
    "### Question 1 of 2\n",
    "True or False: OLTP queries are read heavy and focus primarily on analytics.\n",
    "- [ ] True\n",
    "- [x] False\n",
    "\n",
    "### Question 2 of 2\n",
    "What makes data modeling for relational databases different?\n",
    "- [x] The ability to model data in a way that is intuitive.\n",
    "- [ ] You must model for the queries first\n",
    "- [ ] There s no flexibility or agile nature to this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the Database: Normalization\n",
    "\n",
    "**Normalization**: To reduce data redundancy and increase data integrity.\n",
    "\n",
    "**De-normalization**: Must be done in read heavy workloads to increase performance. \n",
    "\n",
    "### Normalization\n",
    "The process of **structuring** a relational database in accordance with a series of **normal forms** in order **to reduce data redundancy and increase data integrity**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of Normal Form:\n",
    "1. To free the database from unwanted insertions, updates, & deletion dependencies\n",
    "2. To reduce the need for refactoring the database as new types of data are introduced\n",
    "3. To make the relational model more informative to users\n",
    "4. To make the database neutral to the query statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Forms\n",
    "The process of normalization is step by step process:\n",
    "* First Normal Form (1NF)\n",
    "* Second Normal Form (2NF)\n",
    "* Third Normal Form (3NF)\n",
    "\n",
    "**How to reach First Normal Form (1NF)**:\n",
    "* Atomic values: each cell contains unique and single values\n",
    "* Be able to add data without altering tables\n",
    "* Separate different relations into different tables\n",
    "* Keep relationships between tables together with foreign keys\n",
    "\n",
    "**Second Normal Form (2NF)**:\n",
    "* Have reached 1NF\n",
    "* All columns in the table must rely on the Primary Key (No partial dependency)\n",
    "\n",
    "**Third Normal Form (3NF)**:\n",
    "* Must be in 2nd Normal Form\n",
    "* No transitive dependencies\n",
    "* Remember, transitive dependencies you are trying to maintain is that to get from A-> C, you want to avoid going through B.\n",
    "\n",
    "**When to use 3NF**:\n",
    "\n",
    "* When you want to update data, we want to be able to do in just 1 place. We want to avoid updating the table in the Customers Detail table (in the example in the lecture slide).\n",
    "\n",
    "### Quiz Question\n",
    "What is the maximum normal form that should be attempted while doing practical data modeling?\n",
    "- [ ] First Normal Form \n",
    "- [ ] Second Normal Form\n",
    "- [x] Third Normal Form\n",
    "- [ ] Fourth Normal Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2 Demo 1: Creating Normalized Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk through the basics of modeling data in normalized form. <br>\n",
    "<ol><li>Create tables in PostgreSQL\n",
    "<li>Insert rows of data\n",
    "<li>Do a simple JOIN SQL query to show how these tables can work together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library \n",
    "Note: An error might popup after this command has executed. If it does, read it carefully before ignoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to the database, get a cursor, and set autocommit to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection\n",
    "try:\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)\n",
    "\n",
    "# get a cursor\n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not get cursor to the Database\")\n",
    "    print(e)\n",
    "\n",
    "# set the autocommit to true\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's imagine we have a table called Music Library. \n",
    "\n",
    "`Table Name: music_library\n",
    "column 0: Album Id\n",
    "column 1: Album Name\n",
    "column 2: Artist Name\n",
    "column 3: Year \n",
    "column 4: List of songs`\n",
    "\n",
    "<img src=\"images/table1.png\" width=\"650\" height=\"650\">\n",
    "\n",
    "\n",
    "\n",
    "#### Now to translate this information into a Create Table Statement and insert the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Rubber Soul', 'The Beatles', 1965, ['Michelle', 'Think For Yourself', 'In My Life'])\n",
      "(2, 'Let It Be', 'The Beatles', 1970, ['Let It Be', 'Across The Universe'])\n"
     ]
    }
   ],
   "source": [
    "# Dropping the table\n",
    "try:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS music_library\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Dropping the table\")\n",
    "    print(e)\n",
    "    \n",
    "# Create a Table statement\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS music_library(album_id INT,\\\n",
    "                                                          album_name VARCHAR,\\\n",
    "                                                          artist_name VARCHAR,\\\n",
    "                                                          year INT, songs TEXT[])\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "#Include the insert statement\n",
    "try:\n",
    "    cur.execute(\"INSERT INTO music_library (album_id,album_name,artist_name,year,songs)\\\n",
    "                 VALUES (%s, %s, %s, %s, %s)\",\\\n",
    "                (1,\"Rubber Soul\", \"The Beatles\", 1965, [\"Michelle\", \"Think For Yourself\", \"In My Life\"]))\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print(e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO music_library (album_id, album_name, artist_name, year, songs) \\\n",
    "                 VALUES (%s, %s, %s, %s, %s)\", \\\n",
    "                 (2, \"Let It Be\", \"The Beatles\", 1970, [\"Let It Be\", \"Across The Universe\"]))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "# Confirm the data got inserted in the table we created\n",
    "try:\n",
    "    cur.execute(\"SELECT * FROM music_library\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: select *\")\n",
    "    print(e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "    print(row)\n",
    "    row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving to 1st Normal Form (1NF)\n",
    "This data has not been normalized. To get this data into 1st normal form, we will need to remove any collections or list of data. We need to break up the list of songs into individuals rows. \n",
    "\n",
    "\n",
    "`Table Name: music_library2\n",
    "column 0: Album Id\n",
    "column 1: Album Name\n",
    "column 2: Artist Name\n",
    "column 3: Year \n",
    "column 4: Song Name`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Rubber Soul', 'The Beatles', 1965, 'Michelle')\n",
      "(1, 'Rubber Soul', 'The Beatles', 1965, 'Think For Yourself')\n",
      "(1, 'Rubber Soul', 'The Beatles', 1965, 'In My Life')\n",
      "(2, 'Let It Be', 'The Beatles', 1970, 'Let It Be')\n",
      "(2, 'Let It Be', 'The Beatles', 1970, 'Across The Universe')\n"
     ]
    }
   ],
   "source": [
    "# Dropping the table\n",
    "try:\n",
    "    cur.execute(\"DROP TABLE IF EXISTS music_library2\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Dropping the table\")\n",
    "    print(e)\n",
    "\n",
    "# Creating the table\n",
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS music_library2(album_id INT,\\\n",
    "                                                          album_name VARCHAR,\\\n",
    "                                                          artist_name VARCHAR,\\\n",
    "                                                          year INT, song_name VARCHAR);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Issue Creating table\")\n",
    "    print(e)\n",
    "\n",
    "# Inserting the values\n",
    "try:\n",
    "    for song in [\"Michelle\", \"Think For Yourself\", \"In My Life\"]:\n",
    "        cur.execute(\"INSERT INTO music_library2 (album_id, album_name, artist_name, year, song_name)\\\n",
    "                     VALUES (%s, %s, %s, %s, %s)\",\\\n",
    "                     (1, \"Rubber Soul\", \"The Beatles\", 1965, song))\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    for song in [\"Let It Be\", \"Across The Universe\"]:\n",
    "        cur.execute(\"INSERT INTO music_library2 (album_id, album_name, artist_name, year, song_name)\\\n",
    "                     VALUES (%s, %s, %s, %s, %s)\",\\\n",
    "                     (2, \"Let It Be\", \"The Beatles\", 1970, song))\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print(e)\n",
    "    \n",
    "# Confirm the data got inserted in the table we created\n",
    "try:\n",
    "    cur.execute(\"SELECT * FROM music_library2\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: select *\")\n",
    "    print(e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "    print(row)\n",
    "    row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving to 2nd Normal Form (2NF)\n",
    "We have moved our data to be in 1NF which is the first step in moving to 2nd Normal Form. Our table is not yet in 2nd Normal Form. While each of our records in our table is unique, our Primary key (*album id*) is not unique. We need to break this up into two tables, *album library* and *song library*. \n",
    "\n",
    "`Table Name: album_library \n",
    "column 0: Album Id\n",
    "column 1: Album Name\n",
    "column 2: Artist Name\n",
    "column 3: Year `\n",
    "\n",
    "`Table Name: song_library\n",
    "column 0: Song Id\n",
    "column 1: Song Name\n",
    "column 3: Album Id` \n",
    "\n",
    "<img src=\"images/table3.png\" width=\"450\" height=\"450\"> <img src=\"images/table4.png\" width=\"450\" height=\"450\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: album_library\n",
      "\n",
      "(1, 'Rubber Soul', 'The Beatles', 1965)\n",
      "(2, 'Let It Be', 'The Beatles', 1970)\n",
      "\n",
      "Table: song_library\n",
      "\n",
      "(1, 'Michelle', 1)\n",
      "(2, 'Think For Yourself', 1)\n",
      "(3, 'In My Life', 1)\n",
      "(4, 'Let It Be', 2)\n",
      "(5, 'Across the Universe', 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS album_library(album_id INT, \\\n",
    "                                                          album_name VARCHAR,\\\n",
    "                                                          artist_name VARCHAR,\\\n",
    "                                                          year INT);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Issue creating table\")\n",
    "    print(e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS song_library(song_id INT,\\\n",
    "                                                          song_name VARCHAR,\\\n",
    "                                                          album_id INT)\")    \n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Issue creating table\")\n",
    "    print(e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library (album_id, album_name, artist_name, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (1, \"Rubber Soul\", \"The Beatles\", 1965))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library (album_id, album_name, artist_name, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (2, \"Let It Be\", \"The Beatles\", 1970))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, 1, \"Michelle\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, 1, \"Think For Yourself\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (3, 1, \"In My Life\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (4, 2, \"Let It Be\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (5, 2, \"Across the Universe\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "print(\"Table: album_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM album_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(\"\\nTable: song_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM song_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do a `JOIN` on this table so we can get all the information we had in our first Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Rubber Soul', 'The Beatles', 1965, 1, 'Michelle', 1)\n",
      "(1, 'Rubber Soul', 'The Beatles', 1965, 2, 'Think For Yourself', 1)\n",
      "(1, 'Rubber Soul', 'The Beatles', 1965, 3, 'In My Life', 1)\n",
      "(2, 'Let It Be', 'The Beatles', 1970, 4, 'Let It Be', 2)\n",
      "(2, 'Let It Be', 'The Beatles', 1970, 5, 'Across the Universe', 2)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cur.execute(\"SELECT * FROM album_library JOIN song_library\\\n",
    "                 ON album_library.album_id = song_library.album_id;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: select *\")\n",
    "    print(e)\n",
    "    \n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "    print(row)\n",
    "    row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving to 3rd Normal Form (3NF)\n",
    "Check our table for any transitive dependencies. *Album_library* can move *Artist_name* to its own table, called *Artists*, which will leave us with 3 tables. \n",
    "\n",
    "`Table Name: album_library2 \n",
    "column 0: Album Id\n",
    "column 1: Album Name\n",
    "column 2: Artist Id\n",
    "column 3: Year `\n",
    "\n",
    "`Table Name: song_library\n",
    "column 0: Song Id\n",
    "column 1: Song Name\n",
    "column 3: Album Id`\n",
    "\n",
    "`Table Name: artist_library\n",
    "column 0: Artist Id\n",
    "column 1: Artist Name `\n",
    "<img src=\"images/table4.png\" width=\"450\" height=\"450\"> <img src=\"images/table5.png\" width=\"450\" height=\"450\"> <img src=\"images/table6.png\" width=\"350\" height=\"350\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: album_library2\n",
      "\n",
      "(1, 'Rubber Soul', 1, 1965)\n",
      "(2, 'Let It Be', 1, 1970)\n",
      "\n",
      "Table: song_library\n",
      "\n",
      "(1, 'Michelle', 1)\n",
      "(2, 'Think For Yourself', 1)\n",
      "(3, 'In My Life', 1)\n",
      "(4, 'Let It Be', 2)\n",
      "(5, 'Across the Universe', 2)\n",
      "\n",
      "Table: artist_library\n",
      "\n",
      "(1, 'The Beatles')\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS album_library2 (album_id int, \\\n",
    "                                                           album_name varchar, artist_id int, \\\n",
    "                                                           year int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS artist_library (artist_id int, \\\n",
    "                                                           artist_name varchar);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library2 (album_id, album_name, artist_id, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (1, \"Rubber Soul\", 1, 1965))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library2 (album_id, album_name, artist_id, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (2, \"Let It Be\", 1, 1970))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO artist_library (artist_id, artist_name) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (1, \"The Beatles\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "\n",
    "print(\"Table: album_library2\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM album_library2;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(\"\\nTable: song_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM song_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "##Doublechecking that data is in the table\n",
    "print(\"\\nTable: artist_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM artist_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do two `JOIN` on these 3 tables so we can get all the information we had in our first Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'The Beatles', 1, 'Rubber Soul', 1, 1965, 1, 'Michelle', 1)\n",
      "(1, 'The Beatles', 1, 'Rubber Soul', 1, 1965, 2, 'Think For Yourself', 1)\n",
      "(1, 'The Beatles', 1, 'Rubber Soul', 1, 1965, 3, 'In My Life', 1)\n",
      "(1, 'The Beatles', 2, 'Let It Be', 1, 1970, 4, 'Let It Be', 2)\n",
      "(1, 'The Beatles', 2, 'Let It Be', 1, 1970, 5, 'Across the Universe', 2)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT * FROM (artist_library JOIN album_library2 ON \\\n",
    "                               artist_library.artist_id = album_library2.artist_id) JOIN \\\n",
    "                               song_library ON album_library2.album_id=song_library.album_id;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE! We have Normalized our dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the sake of the demo, I will drop the tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"DROP table music_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table music_library2\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table album_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table song_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table album_library2\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table artist_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally close your cursor and connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-normalization\n",
    "JOINS on the database allow for outstanding flexibility but are extremely slow. If you are dealing with heavy reads on your database, you may want to think about denormalizing your tables. You get your data into normalized form, and then you proceed with denormalization. So, denormalization comes after normalization.\n",
    "\n",
    "### Logical Design Change\n",
    "1. The designer is in charge of keeping the data consistent\n",
    "2. Reads will be faster(select)\n",
    "3. Writes will be slower(insert,update,delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2 Demo 2: Creating Denormalized Tables\n",
    "### Walk through the basics of modeling data from normalized from to denormalized form. In this demo, we will: <br>\n",
    "<ol><li>Create tables in PostgreSQL<li>Insert rows of data<li>Do simple JOIN SQL queries to show how these mutliple tables can work together. \n",
    "\n",
    "_Remember the examples shown are simple, but imagine these situations at scale with large datasets, many users, and the need for quick response time._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the library \n",
    "Note: An error might popup after this command has executed. If it does, read it carefully before ignoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a connection to the database, get a cursor, and set autocommit to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: could not connect to the Postgres database\")\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not get cursor to the Database\")\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with our normalized (3NF) database set of tables we had in the last exercise but we have added a new table song_length. \n",
    "\n",
    "`Table Name: album_library \n",
    "column 0: Album Id\n",
    "column 1: Album Name\n",
    "column 2: Artist Id\n",
    "column 3: Year `\n",
    "\n",
    "`Table Name: song_library\n",
    "column 0: Song Id\n",
    "column 1: Song Name\n",
    "column 3: Album Id`\n",
    "\n",
    "`Table Name: artist_library\n",
    "column 0: Artist Id\n",
    "column 1: Artist Name `\n",
    "\n",
    "`Table Name: song_length\n",
    "column 0: Song Id\n",
    "column 1: Song length in seconds\n",
    "`\n",
    "\n",
    "Please refer to the table images in the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all Tables\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS album_library (album_id int, \\\n",
    "                                                           album_name varchar, artist_id int, \\\n",
    "                                                           year int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS artist_library (artist_id int, \\\n",
    "                                                           artist_name varchar);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS song_library (song_id int, album_id int, \\\n",
    "                                                          song_name varchar);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS song_length (song_id int, song_length int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "#Insert into all tables \n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_length (song_id, song_length) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (1, 163))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_length (song_id, song_length) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (2, 137))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_length (song_id, song_length) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (3, 145))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_length (song_id, song_length) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (4, 240))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_length (song_id, song_length) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (5, 227))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, 1, \"Michelle\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, 1, \"Think For Yourself\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (3, 1, \"In My Life\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (4, 2, \"Let It Be\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library (song_id, album_id, song_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (5, 2, \"Across the Universe\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library (album_id, album_name, artist_id, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (1, \"Rubber Soul\", 1, 1965))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library (album_id, album_name, artist_id, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (2, \"Let It Be\", 1, 1970))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO artist_library (artist_id, artist_name) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (1, \"The Beatles\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: album_library\n",
      "\n",
      "(1, 'Rubber Soul', 1, 1965)\n",
      "(2, 'Let It Be', 1, 1970)\n",
      "\n",
      "Table: song_library\n",
      "\n",
      "(1, 1, 'Michelle')\n",
      "(2, 1, 'Think For Yourself')\n",
      "(3, 1, 'In My Life')\n",
      "(4, 2, 'Let It Be')\n",
      "(5, 2, 'Across the Universe')\n",
      "\n",
      "Table: artist_library\n",
      "\n",
      "(1, 'The Beatles')\n",
      "\n",
      "Table: song_length\n",
      "\n",
      "(1, 163)\n",
      "(2, 137)\n",
      "(3, 145)\n",
      "(4, 240)\n",
      "(5, 227)\n"
     ]
    }
   ],
   "source": [
    "print(\"Table: album_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM album_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(\"\\nTable: song_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM song_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(\"\\nTable: artist_library\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM artist_library;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()\n",
    "\n",
    "print(\"\\nTable: song_length\\n\")\n",
    "try: \n",
    "    cur.execute(\"SELECT * FROM song_length;\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's say we need to do a query that gives us:\n",
    "\n",
    "`artist_id \n",
    "artist_name \n",
    "album_id \n",
    "album_name \n",
    "year \n",
    "song_id\n",
    "song_name \n",
    "song_length` \n",
    "\n",
    "we will need to perform a 3 way `JOIN` on the 4 tables we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'The Beatles', 1, 'Rubber Soul', 1965, 1, 'Michelle', 163)\n",
      "(1, 'The Beatles', 1, 'Rubber Soul', 1965, 2, 'Think For Yourself', 137)\n",
      "(1, 'The Beatles', 1, 'Rubber Soul', 1965, 3, 'In My Life', 145)\n",
      "(1, 'The Beatles', 2, 'Let It Be', 1970, 4, 'Let It Be', 240)\n",
      "(1, 'The Beatles', 2, 'Let It Be', 1970, 5, 'Across the Universe', 227)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT artist_library.artist_id, artist_name, album_library.album_id, \\\n",
    "                        album_name, year, song_library.song_id, song_name, song_length\\\n",
    "                  FROM ((artist_library JOIN album_library ON \\\n",
    "                         artist_library.artist_id = album_library.artist_id) JOIN \\\n",
    "                         song_library ON album_library.album_id=song_library.album_id) JOIN\\\n",
    "                         song_length ON song_library.song_id=song_length.song_id;\")\n",
    "    \n",
    "    \n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great we were able to get the data we wanted.\n",
    "\n",
    "But, we had to do a to 3 way `JOIN` to get there. While it's great we had that flexability, we need to remember that `JOINS` are slow and if we have a read heavy workload that required low latency queries we want to reduce the number of `JOINS`.  Let's think about denormalizing our normalized tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 1 : `select artist_name, album_name, year, song_name, song_length FROM <min number of tables>` \n",
    "I want a list of all my songs\n",
    "#### Query 2: `select album_name SUM(song_length) FROM <min number of tables> GROUP BY album_name` \n",
    "I want to know the length of each album in seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all Tables\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS album_library1 (album_id int, \\\n",
    "                                                           album_name varchar, artist_name varchar, \\\n",
    "                                                           year int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS song_library1 (song_id int, album_id int, \\\n",
    "                                                          song_name varchar, song_length int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "#Insert into all tables \n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library1 (song_id, album_id, song_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (2, 1, \"Think For Yourself\", 137 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library1 (song_id, album_id, song_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (3, 1, \"In My Life\", 145))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library1 (song_id, album_id, song_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (4, 2, \"Let It Be\", 240))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO song_library1 (song_id, album_id, song_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (5, 2, \"Across the Universe\", 227))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library1 (album_id, album_name, artist_name, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (1, \"Rubber Soul\", \"The Beatles\", 1965))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_library1 (album_id, album_name, artist_name, year) \\\n",
    "                 VALUES (%s, %s, %s, %s)\", \\\n",
    "                 (2, \"Let It Be\", \"The Beatles\", 1970))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great we can now do a simplifed query to get the information we need. Only one `JOIN` is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Beatles', 'Rubber Soul', 1965, 'Think For Yourself', 137)\n",
      "('The Beatles', 'Rubber Soul', 1965, 'In My Life', 145)\n",
      "('The Beatles', 'Let It Be', 1970, 'Let It Be', 240)\n",
      "('The Beatles', 'Let It Be', 1970, 'Across the Universe', 227)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT artist_name, album_name, year, song_name, song_length\\\n",
    "                  FROM song_library1 JOIN album_library1 ON \\\n",
    "                        song_library1.album_id = album_library1.album_id;\")\n",
    "        \n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: `select album_name SUM(song_length) FROM <min number of tables> GROUP BY album_name` \n",
    "\n",
    "We could also do a `JOIN` on the tables we have created, but what if we do not want to have any `JOINS`, why not create a new table with just the information we need. \n",
    "\n",
    "`Table Name: album_length\n",
    "col: Song Id\n",
    "Col: Album Id\n",
    "col: Song Length\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS album_length (song_id int, album_name varchar, \\\n",
    "                                                          song_length int);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "\n",
    "\n",
    "#Insert into all tables \n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_length (song_id, album_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, \"Rubber Soul\", 163 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_length (song_id, album_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, \"Rubber Soul\", 137 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)   \n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_length (song_id, album_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (3, \"Rubber Soul\", 145 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)   \n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_length (song_id, album_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (4, \"Let It Be\", 240 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e) \n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO album_length (song_id, album_name, song_length) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (5, \"Let It Be\", 227 ))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's run our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rubber Soul', 445)\n",
      "('Let It Be', 467)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT album_name, SUM(song_length) FROM album_length GROUP BY album_name;\")\n",
    "        \n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have successfully taken normalized table and denormalized them inorder to speed up our performance and allow for simplier queries to be executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the sake of the demo, I will drop the tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"DROP table song_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table album_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table artist_library\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table song_length\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table song_library1\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table album_library1\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table album_length\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally close your cursor and connection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact and Dimension Tables\n",
    "* Work together to create an organized data model.\n",
    "* While fact and dimension are not created differently in DDL, they are conceptual and extremely important for organization.\n",
    "\n",
    "### Fact Tables\n",
    "Fact table consists of the measurement, metrics or facts of a business process.\n",
    "### Dimension Table\n",
    "A structure that categorizes facts and measures in order to enable users to answer business questions. Dimensions are people, products and time.\n",
    "\n",
    "### Example\n",
    "The following image shows the relationship between the fact and dimension tables. As you can see in the image, the unique primary key for each Dimension table is included in the Fact table.\n",
    "\n",
    "In this example, it helps to think about the Dimension tables providing the following information:\n",
    "\n",
    "* **Where** the product was bought? (Dim_Store table)\n",
    "* **When** the product was bought? (Dim_Date table)\n",
    "* **What** product was bought? (Dim_Product table)\n",
    "\n",
    "The **Fact table** provides the **metric of the business process** (here Sales)\n",
    "\n",
    "* **How many** units of products were bought? (Fact_Sales table)\n",
    "<img src=\"images/dimension-fact-tables.png\">\n",
    "\n",
    "### Implementing Different Schemas\n",
    "Two of the most popular (because of their simplicity) data mart schema for data warehouses are:\n",
    "1. Start Schema\n",
    "2. Snowflake Schema\n",
    "\n",
    "If you are familiar with **Entity Relationship Diagrams** (ERD), you will find the depiction of STAR and SNOWFLAKE schemas in the demo familiar. The ERDs show the data model in a concise way that is also easy to interpret. ERDs can be used for any data model, and are not confined to STAR or SNOWFLAKE schemas. Commonly available tools can be used to generate ERDs. However, more important than creating an ERD is to learn more about the data through conversations with the data team so as a data engineer you have a strong understanding of the data you are working with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Schemas\n",
    "Start Schema is the simplest style of data mart schema. The star schema consists of one or more fact tables referencing any number of dimension tables.\n",
    "\n",
    "### Why \"star\" schema?\n",
    "* Gets its name from physical model resembling a start shape\n",
    "* A fact model is at its center\n",
    "* Dimension table surrounds the fact table representing the star's points.\n",
    "<img src=\"images/star_schema.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Star Schemas\n",
    "* De-normalized\n",
    "* Simplifies queries\n",
    "* Fast aggregation\n",
    "\n",
    "## Drawbacks of Star Schemas\n",
    "* Issues that come with de-normalization\n",
    "* Data Integrity\n",
    "* Decrease query flexibility\n",
    "* Many to many relationship --simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Schema\n",
    "Logical arrangement of tables in a multi-dimensional database represented by centralized fact tables which are connected to multiple dimensions.\n",
    "\n",
    "### Why \"snowflake\" schema?\n",
    "\" A complex snowflake shape emerges when the dimensions of a snowflake schema are elaborated., having multiple levels of relationships, child tables having multiple parents.\"\n",
    "<img src=\"images/snowflake_schema.png\">\n",
    "\n",
    "### Snowflake vs star\n",
    "* Star Schema is a special, simplified case of snowflake schema.\n",
    "* Star Schema does not allow for one to many relationships while snowflake schema does.\n",
    "* Snowflake schema is more normalized than Star Schema but only in 1NF or 2NF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2 Demo 3: Creating Fact and Dimension Tables with Star Schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk through the basics of modeling data using Fact and Dimension tables.  In this demo, we will:<br>\n",
    "<ol><li>Create both Fact and Dimension tables<li>Show how this is a basic element of the Star Schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library \n",
    "Note: An error might popup after this command has executed. If it does, read it carefully before ignoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next use that connection to get a cursor that we will use to execute queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: could not get cursor to the Database\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this demo we will use automatic commit so that each action is commited without having to call conn.commit() after each command. The ability to rollback and commit transactions are a feature of Relational Databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's imagine we work at an online Music Store. There will be many tables in our database but let's just focus on 4 tables around customer purchases. \n",
    "\n",
    "`Table Name: customer_transactions\n",
    "column: Customer Id\n",
    "column: Store Id\n",
    "column: Spent`\n",
    "\n",
    "`Table Name: Customer\n",
    "column: Customer Id\n",
    "column: Name\n",
    "column: Rewards`\n",
    "\n",
    "`Table Name: store\n",
    "column: Store Id\n",
    "column: State`\n",
    "\n",
    "`Table Name: items_purchased\n",
    "column: customer id\n",
    "column: Item Name`\n",
    "\n",
    "#### From this representation we can already start to see the makings of a \"STAR\". We have one fact table (the center of the star) and 3  dimension tables that are coming from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create the Fact Table and insert the data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS customer_transactions(customer_id INT, \\\n",
    "                                                                  store_id INT,\\\n",
    "                                                                  spent NUMERIC);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Error: Issue creating table\")\n",
    "    print(e)\n",
    "    \n",
    "#Insert into all tables \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO customer_transactions (customer_id, store_id, spent) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, 1, 20.50))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO customer_transactions (customer_id, store_id, spent) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, 1, 35.21))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create our Dimension Tables and insert data into those tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS items_purchased (customer_id int, item_number int, item_name varchar);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO items_purchased (customer_id, item_number, item_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, 1, \"Rubber Soul\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO items_purchased (customer_id, item_number, item_name) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, 3, \"Let It Be\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS store (store_id int, state varchar);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO store (store_id, state) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (1, \"CA\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO store (store_id, state) \\\n",
    "                 VALUES (%s, %s)\", \\\n",
    "                 (2, \"WA\"))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS customer (customer_id int, name varchar, rewards boolean);\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Issue creating table\")\n",
    "    print (e)\n",
    "    \n",
    "try: \n",
    "    cur.execute(\"INSERT INTO customer (customer_id, name, rewards) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (1, \"Amanda\", True))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)\n",
    "\n",
    "try: \n",
    "    cur.execute(\"INSERT INTO customer (customer_id, name, rewards) \\\n",
    "                 VALUES (%s, %s, %s)\", \\\n",
    "                 (2, \"Toby\", False))\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Inserting Rows\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can do a variety of queries on this data easily because of utilizing the fact/dimension and Star Schema**\n",
    "\n",
    "* _Query 1_: Find all the customers that spent more than 30 dollars, who are they, what did they buy and if they are a rewards member\n",
    "\n",
    "* _Query 2_: How much did Store 1 sell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Query 1:_  Find all the customers that spent more than 30 dollars, who are they, what did they buy and if they are a rewards member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Toby', 'Let It Be', False)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT name, item_name, rewards FROM ((customer_transactions \\\n",
    "                                                JOIN customer ON customer.customer_id=customer_transactions.customer_id)\\\n",
    "                                                JOIN items_purchased ON \\\n",
    "                                                customer_transactions.customer_id=items_purchased.customer_id)\\\n",
    "                                                WHERE spent > 30 ;\")\n",
    "    \n",
    "    \n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Query 2:_ How much did Store 1 sell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, Decimal('55.71'))\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"SELECT store_id, SUM(spent) FROM customer_transactions GROUP BY store_id;\")\n",
    "    \n",
    "    \n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: select *\")\n",
    "    print (e)\n",
    "\n",
    "row = cur.fetchone()\n",
    "while row:\n",
    "   print(row)\n",
    "   row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: What you can see here is from this elegant schema we were able to get \"facts/metrics\" from our fact table (how much each store sold), and also information about our customers that will allow us to do more indepth analytics to get answers to business questions by utilizing our fact and dimension tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the sake of the demo, I will drop the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"DROP table customer_transactions\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table items_purchased\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table customer\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)\n",
    "try: \n",
    "    cur.execute(\"DROP table store\")\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Dropping table\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally close your cursor and connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Definition and Constraints\n",
    "The CREATE statement in SQL has a few important constraints that are highlighted below.\n",
    "\n",
    "### NOT NULL\n",
    "The **NOT NULL** constraint indicates that the column cannot contain a null value.\n",
    "\n",
    "Here is the syntax for adding a NOT NULL constraint to the CREATE statement:\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_transactions (\n",
    "    customer_id int NOT NULL, \n",
    "    store_id int, \n",
    "    spent numeric\n",
    ");`\n",
    "\n",
    "You can add **NOT NULL** constraints to more than one column. Usually this occurs when you have a **COMPOSITE KEY**, which will be discussed further below.\n",
    "\n",
    "Here is the syntax for it:\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_transactions (\n",
    "    customer_id int NOT NULL, \n",
    "    store_id int NOT NULL, \n",
    "    spent numeric\n",
    ");`\n",
    "\n",
    "### UNIQUE\n",
    "The **UNIQUE** constraint is used to specify that the data across all the rows in one column are unique within the table. The **UNIQUE** constraint can also be used for multiple columns, so that the combination of the values across those columns will be unique within the table. In this latter case, the values within 1 column do not need to be unique.\n",
    "\n",
    "Let's look at an example.\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_transactions (\n",
    "    customer_id int NOT NULL UNIQUE, \n",
    "    store_id int NOT NULL UNIQUE, \n",
    "    spent numeric \n",
    ");`\n",
    "Another way to write a **UNIQUE constraint** is to add a table constraint using commas to separate the columns.\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_transactions (\n",
    "    customer_id int NOT NULL, \n",
    "    store_id int NOT NULL, \n",
    "    spent numeric,\n",
    "    UNIQUE (customer_id, store_id, spent)\n",
    ");`\n",
    "\n",
    "### PRIMARY KEY\n",
    "The **PRIMARY KEY** constraint is defined on a single column, and every table should contain a primary key. The values in this column uniquely identify the rows in the table. If a group of columns are defined as a primary key, they are called a **composite key**. That means the combination of values in these columns will uniquely identify the rows in the table. By default, the **PRIMARY KEY** constraint has the unique and not null constraint built into it.\n",
    "\n",
    "Let's look at the following example:\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS store (\n",
    "    store_id int PRIMARY KEY, \n",
    "    store_location_city text,\n",
    "    store_location_state text\n",
    ");`\n",
    "Here is an example for a group of columns serving as **composite key**.\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_transactions (\n",
    "    customer_id int, \n",
    "    store_id int, \n",
    "    spent numeric,\n",
    "    PRIMARY KEY (customer_id, store_id)\n",
    ");`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert\n",
    "In RDBMS language, the term upsert refers to the idea of inserting a new row in an existing table, or updating the row if it already exists in the table. The action of updating or inserting has been described as \"upsert\".\n",
    "\n",
    "The way this is handled in PostgreSQL is by using the `INSERT` statement in combination with the `ON CONFLICT` clause.\n",
    "\n",
    "### INSERT\n",
    "The **INSERT** statement adds in new rows within the table. The values associated with specific target columns can be added in any order.\n",
    "\n",
    "Let's look at a simple example. We will use a customer address table as an example, which is defined with the following **CREATE** statement:\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS customer_address (\n",
    "    customer_id int PRIMARY KEY, \n",
    "    customer_street varchar NOT NULL,\n",
    "    customer_city text NOT NULL,\n",
    "    customer_state text NOT NULL\n",
    ");`\n",
    "\n",
    "Let's try to insert data into it by adding a new row:\n",
    "\n",
    "`INSERT into customer_address (\n",
    "VALUES\n",
    "    (432, '758 Main Street', 'Chicago', 'IL'\n",
    ");`\n",
    "\n",
    "Now let's assume that the customer moved and we need to update the customer's address. However we do not want to add a new customer id. In other words, if there is any conflict on the `customer_id`, we do not want that to change.\n",
    "\n",
    "This would be a good candidate for using the ON CONFLICT DO NOTHING clause.\n",
    "\n",
    "`INSERT INTO customer_address (customer_id, customer_street, customer_city, customer_state)\n",
    "VALUES\n",
    " (\n",
    " 432, '923 Knox Street', 'Albany', 'NY'\n",
    " ) \n",
    "ON CONFLICT (customer_id) \n",
    "DO NOTHING;`\n",
    "\n",
    "Now, let's imagine we want to add more details in the existing address for an existing customer. This would be a good candidate for using the **ON CONFLICT DO UPDATE** clause.\n",
    "\n",
    "`INSERT INTO customer_address (customer_id, customer_street)\n",
    "VALUES\n",
    "    (\n",
    "    432, '923 Knox Street, Suite 1' \n",
    ") \n",
    "ON CONFLICT (customer_id) \n",
    "DO UPDATE\n",
    "    SET customer_street  = EXCLUDED.customer_street;`\n",
    "    \n",
    "We recommend checking out these two links to learn other ways to insert data into the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
